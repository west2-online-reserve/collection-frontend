文件简介；
文件crawler.js是爬取网页内容的脚本，使用的是node.js和cheerio库等。该脚本爬取fzu通知网页的内容，并将这些链接保存到一个文件中。
文件server.js用Sequelize简化操作，建立数据库表结构，并将爬取的数据存储到 SQLite数据库中，同时定义了相关接口。
文件queue.js是因为p-queue好像只有ESM的导入方法，所以就打包了一下，使用require方法导入到crawler.js中。


数据说明：
    notices.json文件中存储的是爬取的通知内容，格式如下：
        {
        "total": 15,
        "generatedAt": "2025-06-17T02:41:58.573Z",
        "startDate": "2025-06-15T16:00:00.000Z",
        "endDate": "2025-06-17T02:41:58.573Z",
        data: notices
        };


        其中notices是一个数组，每个元素代表一个通知，格式如下：
        {
        publishDate": "2025-06-17",
        "department": "【教师工作部】",
        "title": "关于2025年高等学校青年骨干教师出国研修项目选派工作的通知",
        "url": "https://info22.fzu.edu.cn/content.jsp?urltype=news.NewsContentUrl&wbtreeid=1307&wbnewsid=38720",
        "content": "各学院、各单位：\n根"
        }

    那个点击数的字段用cheerio好像解析不出来，可能是因为是动态渲染还是别的什么原因，也有可能是我的原因，反正就没有爬取了。


使用：
    目前crawler.js是这样：
    // 启动爬虫
    //crawlNotices();
    module.exports = {
        crawlNotices
    };
    //crawlNotices();
    两个文件放在一个文件夹下
    把crawlNotices()作为函数导出到server.js中
    在文件夹输入命令：node server
    就可以爬取数据，将数据存储到数据库和notices.json文件中。

    也可以将//crawlNotices();取消注释，输入命令：node crawler
    就可以爬取数据存储到对应文件，但是没有数据库操作和相应的url接口。